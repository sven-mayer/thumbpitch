# ThumbPitch: Enriching Thumb Interaction on Mobile Touchscreens using Deep Learning
Jamie Ullerich, Maximiliane Windl, Andreas Bulling, and Sven Mayer

## Abstact
everyday ubiquitous interaction. Yet, capacitive touchscreens are limited in expressiveness; thus, a large body of work has focused on extending the input capabilities of touchscreens. One promising approach is to use index finger orientation; however, this requires a two-handed interaction and poses ergonomic constraints. We propose using the thumb’s pitch as an additional input dimension to counteract these limitations, enabling one-handed interaction scenarios. Our deep convolutional neural network detecting the thumb’s pitch is trained on more than 230,000 ground truth images recorded using a motion tracking system.We highlight the potential of ThumbPitch by proposing several use cases that exploit the higher expressiveness, especially for one-handed scenarios. We tested three use cases in a validation study and validated our model. Our model achieved a mean error of only 11.9°.


## How to cite this work

This work can be cited as follows:
<pre>
@inproceedings{ullerich2022thumbpitch,
title = {ThumbPitch: Enriching Thumb Interaction on Mobile Touchscreens using Deep Learning},
author = {Ullerich, Jamie and Windl, Maximiliane and Bulling, Andreas and Mayer, Sven},
year = {2022},
booktitle = {33nd Australian Conference on Human-Computer Interaction},
publisher = {Association for Computing Machinery},
address = {Canberra, NSW, Australia},
series = {OzCHI '22},
url = {https://sven-mayer.com/wp-content/uploads/2022/08/ullerich2022thumbpitch.pdf}
}
</pre>
